{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nThis module is gonna be the center of control of my programm. That's where I am gonna lunch the execution of the different parts of the code. Depending on what I want to do I will run part(s) of the project or the whole one. For instance, if I want to test the complete programm I will be able to run all with one click. At the opposite, if I want to test a new module functionnning, I will run this one only. \\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "This module is gonna be the center of control of my programm. That's where I am gonna lunch the execution of the different parts of the code. Depending on what I want to do I will run part(s) of the project or the whole one. For instance, if I want to test the complete programm I will be able to run all with one click. At the opposite, if I want to test a new module functionnning, I will run this one only. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#src.useful_functions\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import useful_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\">Convert csv into dataframe</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The old data_interim.pkl file, and the new one ARE the same\n",
      "The old 'data_interim.pkl' file was well deleted\n",
      "The new 'data_interim.pkl' file was well saved \n",
      "\n",
      "This dataframe contains matchs of the seasons:  [2015 2016 2017 2018 2019 2020 2021 2022 2023]\n"
     ]
    }
   ],
   "source": [
    "#src.data.make_dataset\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from data import make_dataset\n",
    "\n",
    "files = [make_dataset.adr1, make_dataset.adr2, make_dataset.adr3, make_dataset.adr4, \n",
    "         make_dataset.adr5, make_dataset.adr6, make_dataset.adr7, make_dataset.adr8, \n",
    "         make_dataset.adr9]\n",
    "\n",
    "# convert csv files into a big dataframe\n",
    "dataset_to_save = make_dataset.read_data(files)\n",
    "\n",
    "# We save the dataframe created into data/interim folder, after having deleted the old one.\n",
    "make_dataset.save_dataframe_into_data_interim(dataset_to_save)\n",
    "\n",
    "#Open the dataframe saved\n",
    "dataset_01 = make_dataset.load_data(seasons_present_in_df_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\">Visualize raw data histograms</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#src.visualization.visualize\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from visualization import visualize\n",
    "\n",
    "\n",
    "#There are several functions to run in this module that are very specific. They are made to identify specific features outliers. We better have to go to the module to run it.\n",
    "\n",
    "visualize.plot_all_num_features(dataset_01.copy(), save = False, density_estimate = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\">Create columns into dataset:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the function add_columns_and_complete_col_ranks() was executed correctly\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features.initialize_new_features_columns\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from features import initialize_new_features_columns\n",
    "\n",
    "#We create the new columns in dataset and stock the columns ranks variables into dico_col_rk\n",
    "dataset_02, dico_col_rk = initialize_new_features_columns.add_columns_and_complete_col_ranks(dataset_01.copy())\n",
    "\n",
    "#We execute a test to verify the columns and columns ranks variables have been correcctly created\n",
    "initialize_new_features_columns.test_columns_ranks(dico_col_rk, theoritical_df_col_nb = 190, dataset_0 = dataset_02.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#FF1493;\">\n",
    "<font size=\"4\"> \n",
    "<strong>\n",
    "    Cr√©ation/Manipulation des Statistiques de Resultat\n",
    "</span style=\"color:#FF1493;\"> </font size=\"4\"> </strong>\n",
    "\n",
    "(pm = pre-match)\n",
    "(sbos = since the beginning of the season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrames are equal except for columns ['RH', 'RA']\n",
      "The DataFrames are equal except for columns ['HT_H_A_status', 'AT_H_A_status']\n",
      "The DataFrames are equal except for columns ['HT_played_matchs_nb', 'AT_played_matchs_nb', 'HT_victories_nb', 'AT_victories_nb']\n",
      "The DataFrames are equal except for columns ['HT_avg_victory_pm', 'AT_avg_victory_pm', 'Diff_HT_avg_victory_pm', 'Diff_AT_avg_victory_pm']\n",
      "float64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'HT_points_ponderated_by_adversary_perf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\polol\\anaconda3\\envs\\env-projet-mbappe\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'HT_points_ponderated_by_adversary_perf'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#We add the avg points per match ponderated by adversary perf, and its HT-AT difference\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset_06[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHT_avg_victory_pm\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m---> 42\u001b[0m dataset_07 \u001b[38;5;241m=\u001b[39m \u001b[43mmake_new_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoints_pm_ponderated_by_adversary_perf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdico_col_rk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_06\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m#We test if the previous action has not modified other col than the ones filled with their values\u001b[39;00m\n\u001b[0;32m     44\u001b[0m useful_functions\u001b[38;5;241m.\u001b[39mcompare_2_df_excepted_col([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHT_avg_pm_points_ponderated_by_adversary_perf\u001b[39m\u001b[38;5;124m'\u001b[39m,  \n\u001b[0;32m     45\u001b[0m                                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAT_avg_pm_points_ponderated_by_adversary_perf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHT_Diff_points_ponderated_by_adversary_perf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAT_Diff_points_ponderated_by_adversary_perf\u001b[39m\u001b[38;5;124m'\u001b[39m], dataset_06, dataset_07)\n",
      "File \u001b[1;32mc:\\Users\\polol\\OneDrive\\Documents\\ML\\Projet Mbappe (11.23- )\\Projet Mbappe Cookiestructure\\src\\features\\make_new_features.py:119\u001b[0m, in \u001b[0;36mpoints_pm_ponderated_by_adversary_perf\u001b[1;34m(dico_col_rk, dataset_0)\u001b[0m\n\u001b[0;32m    116\u001b[0m rownb_last_season_match\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m#On change le dtype des colonnes qu'on va remplir car j'ai eu des erreurs √† cause de ca\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHT_points_ponderated_by_adversary_perf\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHT_points_ponderated_by_adversary_perf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    120\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAT_points_ponderated_by_adversary_perf\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAT_points_ponderated_by_adversary_perf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nb_matchs_traites, rownb_last_season_match):\n",
      "File \u001b[1;32mc:\\Users\\polol\\anaconda3\\envs\\env-projet-mbappe\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\polol\\anaconda3\\envs\\env-projet-mbappe\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'HT_points_ponderated_by_adversary_perf'"
     ]
    }
   ],
   "source": [
    "#src.features.make_new_features\n",
    "if __name__ == '__main__':\n",
    "    from features import make_new_features\n",
    "\n",
    "\n",
    "#We add the matchs results \n",
    "dataset_03 = make_new_features.matchs_results(dataset_02.copy())\n",
    "#We test if the previous action has not modified other col than the ones filled with their values\n",
    "useful_functions.compare_2_df_excepted_col(['RH',\n",
    "                                            'RA'], dataset_02, dataset_03)\n",
    "\n",
    "\n",
    "\n",
    "#We add the Home or Away status of the teams\n",
    "dataset_04 = make_new_features.home_away_status(dataset_03.copy())\n",
    "#We test if the previous action has not modified other col than the ones filled with their values\n",
    "useful_functions.compare_2_df_excepted_col(['HT_H_A_status',\n",
    "                                            'AT_H_A_status'], dataset_03, dataset_04)\n",
    "\n",
    "\n",
    "\n",
    "# We add the number of matches and number of victories\n",
    "dataset_05 = make_new_features.nb_matchs_nb_victories(dico_col_rk.copy(), dataset_04.copy())\n",
    "#We test if the previous action has not modified other col than the ones filled with their values\n",
    "useful_functions.compare_2_df_excepted_col(['HT_played_matchs_nb',\n",
    "                                            'AT_played_matchs_nb',\n",
    "                                            'HT_victories_nb',\n",
    "                                            'AT_victories_nb'], dataset_04, dataset_05)\n",
    "\n",
    "\n",
    "#We add the avg victories per match and its HT-AT difference\n",
    "dataset_06 = make_new_features.victories_per_match_AVG_and_DIFF(dataset_05.copy())\n",
    "#We test if the previous action has not modified other col than the ones filled with their values\n",
    "useful_functions.compare_2_df_excepted_col(['HT_avg_victory_pm',\n",
    "                                            'AT_avg_victory_pm',\n",
    "                                            'Diff_HT_avg_victory_pm',\n",
    "                                            'Diff_AT_avg_victory_pm'], dataset_05, dataset_06)\n",
    "\n",
    "\n",
    "#We add the avg points per match ponderated by adversary perf, and its HT-AT difference\n",
    "print(dataset_06['HT_avg_victory_pm'].dtype)\n",
    "dataset_07 = make_new_features.points_pm_ponderated_by_adversary_perf(dico_col_rk.copy(), dataset_06.copy())\n",
    "#We test if the previous action has not modified other col than the ones filled with their values\n",
    "useful_functions.compare_2_df_excepted_col(['HT_avg_pm_points_ponderated_by_adversary_perf',  \n",
    "                                            'AT_avg_pm_points_ponderated_by_adversary_perf', 'HT_Diff_points_ponderated_by_adversary_perf', 'AT_Diff_points_ponderated_by_adversary_perf'], dataset_06, dataset_07)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-projet-mbappe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
