{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nThis module is gonna be the center of control of my programm. That's where I am gonna lunch the execution of the different parts of the code. Depending on what I want to do I will run part(s) of the project or the whole one. For instance, if I want to test the complete programm I will be able to run all with one click. At the opposite, if I want to test a new module functionnning, I will run this one only. \\n\\nModules as useful_functions and constant_variables are not imported here as already imported inside modules that use them.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "This module is gonna be the center of control of my programm. That's where I am gonna lunch the execution of the different parts of the code. Depending on what I want to do I will run part(s) of the project or the whole one. For instance, if I want to test the complete programm I will be able to run all with one click. At the opposite, if I want to test a new module functionnning, I will run this one only. \n",
    "\n",
    "Modules as useful_functions and constant_variables are not imported here as already imported inside modules that use them.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The old data_interim.pkl file, and the new one ARE the same /n\n",
      "The old 'data_interim.pkl' file was well deleted\n",
      "The new 'data_interim.pkl' file was well saved\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'remove'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m make_dataset\u001b[38;5;241m.\u001b[39msave_dataframe_into_data_interim(dataset_to_save)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#Open the dataframe saved\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mmake_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseasons_present_in_df_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\polol\\OneDrive\\Documents\\ML\\Projet Mbappe (11.23- )\\Projet Mbappe Cookiestructure\\src\\data\\make_dataset.py:78\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(seasons_present_in_df_info)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# Remove the holdest year which is only the beginning of the first season\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     min_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(seasons_in_dataframe)\n\u001b[1;32m---> 78\u001b[0m     \u001b[43mseasons_in_dataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m(min_value)\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis dataframe contains matchs of the seasons: \u001b[39m\u001b[38;5;124m\"\u001b[39m, seasons_in_dataframe)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'remove'"
     ]
    }
   ],
   "source": [
    "\n",
    "#src.data.make_dataset\n",
    "if __name__ == '__main__':\n",
    "    from data import make_dataset\n",
    "\n",
    "files = [make_dataset.adr1, make_dataset.adr2, make_dataset.adr3, make_dataset.adr4, \n",
    "         make_dataset.adr5, make_dataset.adr6, make_dataset.adr7, make_dataset.adr8, \n",
    "         make_dataset.adr9]\n",
    "\n",
    "# convert csv files into a big dataframe\n",
    "dataset_to_save = make_dataset.read_data(files)\n",
    "\n",
    "# We save the dataframe created into data/interim folder, after having deleted the old one.\n",
    "make_dataset.save_dataframe_into_data_interim(dataset_to_save)\n",
    "\n",
    "#Open the dataframe saved\n",
    "dataset = make_dataset.load_data(seasons_present_in_df_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#We import the dataset, it's useful for all the execution below\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 3\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mmake_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mload_data()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'make_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#We import the dataset, it's useful for all the execution below\n",
    "if __name__ == '__main__':\n",
    "    dataset = make_dataset.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    from visualization import visualize\n",
    "\n",
    "\n",
    "#We execute the whole visualize module.\n",
    "#There are several functions to run in this module that are very specific. They are made to identify specific features outliers. We better have to go to the module to run it.\n",
    "\n",
    "visualize.plot_all_num_features(dataset, save = False, density_estimate = False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-projet-mbappe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
