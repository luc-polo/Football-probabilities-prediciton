{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#30/05/2024\n",
    "#Class that gethers almost all parameters required in formatting_splitting... funcitons\n",
    "\n",
    "\"It was placed just above formatting_cleaning(). It was used to define a variable that contained most of the parameters to input in formatting_cleaning() and int formatting_splitting(). Now I have modified formatting_splitting and renamed it splitting().There now are way less parameters to input\"\n",
    "class formatting_splitting_args:\n",
    "    def __init__(self, H_A_col_to_concat, names_col_concatenated_0, col_to_remove, contextual_col, test_seasons, train_seasons):\n",
    "        \"\"\"Gethers almost all parameters required in formatting_splitting\n",
    "\n",
    "        Args:\n",
    "            H_A_col_to_concat (list): List of column names we want to include in the final dataset for our pipeline. It contains the Home and Away teams column names that we will concatenate.\n",
    "            names_col_concatenated_0 (list): List of names we will assign to the concatenated columns (H_A_col_to_concat).\n",
    "            col_to_remove (list): List of column names to be deleted.\n",
    "            contextual_col (list): List with the names of the concatenated columns containing contextual information that we do not want to give to our model.\n",
    "            test_seasons (list): List of seasons we want to include in the test set.\n",
    "            train_seasons (list): List of seasons we want to include in the train set\n",
    "        \"\"\"\n",
    "        self.H_A_col_to_concat = H_A_col_to_concat\n",
    "        self.names_col_concatenated_0 = names_col_concatenated_0\n",
    "        self.col_to_remove = col_to_remove\n",
    "        self.contextual_col = contextual_col\n",
    "        self.test_seasons = test_seasons\n",
    "        self.train_seasons = train_seasons\n",
    "\n",
    "\n",
    "#25/05/2024\n",
    "# Function that shuffle data in the splitting process\n",
    "\n",
    "\"\"\"I deleted it because the random shuffling of samples before distribution into training or test sets was not appropriate. It kind of caused corruption of data to train the model on some matches of a certain season, that played out after some matches we try to predict result in test set.\"\"\"\n",
    "def formatting_splitting_shuffle(H_A_col_to_concat, col_concatenated_names, col_to_delete_list, contextual_col, random_state_0, dataset_0, test_proportion, *train_proportion):\n",
    "    \"\"\"  \n",
    "    This function selects the features H_A_col_to_concat, concatenates HT and AT col, removes rows where the nb of matchs played by teams is inferior to min_played_matchs_nb, removes column(s) of feature(s) we don't want to keep in our dataset (if there are), returns separated features and labels.\n",
    "    Then it splits our data into train, (valid if needed) and test sets and convert them into dataframes. It returns X_train, Y_train, X_test, Y_test, (X_valid, Y_valid) ready to be given to our model and the calibrator. X_train_info, X_test_info, and (X_valid_info) contain contextual information such as team names, which we may need after executing the pipeline to analyze the coherence of the predicted probabilities.\n",
    "    \n",
    "    Args:\n",
    "        H_A_col_to_concat (list): The list containing the names of HT and AT col we want to put into X_train and X_test\n",
    "        \n",
    "        col_concatenated_names (list): The list containing the names we we will give to the columns of the concatenation of H_A_col_to_concat\n",
    "      \n",
    "        dataset_restricted_0 (DataFrame): Restricted dataset obtained in III)3)\n",
    "        \n",
    "        col_to_delete_list (list): (If there are) List of columns names we want to delete from dataset because we don't want the model to use it.\n",
    "        \n",
    "        contextual_col (list): List with the names of the concatenated columns containing a contextual information. That's the col we do not want to give to our model.\n",
    "        \n",
    "        dataset_0 (DataFrame): The dataset containing the data.\n",
    "        \n",
    "        test_proportion (int): The prooportion of the dataset we want to dedicate to the test set\n",
    "                \n",
    "        *train_proportion (int): To precise only if we want to make a validation set. The prooportion of the dataset we want to dedicate to the train set\n",
    "    \n",
    "    Returns:\n",
    "        Tuple: (X_train_info, X_train, Y_train, X_test_info, X_test, Y_test, *X_valid_info, *X_valid, *Y_valid)\n",
    "    \"\"\"\n",
    "    \n",
    "    #Definition of Y and X\n",
    "    #On  selectionne uniquement les lignes où le nb de match joués > min_played_matchs_nb (défini dans 'Definition of restricted datasets...') On concatenne les HT et AT col\n",
    "    \n",
    "    Df_concatenated_target_column = useful_functions.HT_AT_col_merger(['RH', 'RA'], ['Result'], constant_variables.min_played_matchs_nb, dataset_0)\n",
    "    \n",
    "    Df_concatenated_features_column = useful_functions.HT_AT_col_merger(H_A_col_to_concat, col_concatenated_names, constant_variables.min_played_matchs_nb, dataset_0)\n",
    "\n",
    "    (X,Y) = Df_concatenated_features_column, Df_concatenated_target_column\n",
    "    \n",
    "    #Supprimer les colonnes demandées\n",
    "    for col in col_to_delete_list:\n",
    "        X=X.drop(col, axis=1)\n",
    "    \n",
    "    # Convertir X et Y en tableaux NumPy pour les conformer au type de données pris en entrée par la fonction train_test_split\n",
    "    X_np_values = X.values\n",
    "    Y_np_values = Y.values\n",
    "    \n",
    "    # Split the data into training, validation, and test sets\n",
    "    if train_proportion:\n",
    "        X_train, X_temp, Y_train, Y_temp = train_test_split(X_np_values,\n",
    "                                                            Y_np_values,\n",
    "                                                            test_size=(1-train_proportion),\n",
    "                                                            random_state = random_state_0,\n",
    "                                                            shuffle = True,\n",
    "                                                            stratify = Y_np_values)\n",
    "        \n",
    "        X_valid, X_test, Y_valid, Y_test = train_test_split(X_temp,\n",
    "                                                            Y_temp,\n",
    "                                                            test_size=(test_proportion/(1-train_proportion)),\n",
    "                                                            random_state = random_state_0,\n",
    "                                                            shuffle = True,\n",
    "                                                            stratify = Y_temp)\n",
    "    else:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X_np_values,\n",
    "                                                            Y_np_values,\n",
    "                                                            test_size=test_proportion,\n",
    "                                                            random_state = random_state_0,\n",
    "                                                            shuffle = True,\n",
    "                                                            stratify = Y_np_values)\n",
    "        \n",
    "\n",
    "    #Convertir X_train, X_test, Y_train, Y_test, X_valid, Y_valid en Dataframes\n",
    "    X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "    X_test = pd.DataFrame(X_test, columns=X.columns)\n",
    "    Y_train = pd.DataFrame(Y_train, columns=Y.columns)\n",
    "    Y_test = pd.DataFrame(Y_test, columns=Y.columns)\n",
    "    if train_proportion:\n",
    "        X_valid = pd.DataFrame(X_valid, columns=X.columns)\n",
    "        Y_valid = pd.DataFrame(Y_valid, columns=Y.columns)\n",
    "    \n",
    "    #We stock and delete the col containing contextual info on matchs (teams names, dates...)\n",
    "    X_train_info = X_train[contextual_col]\n",
    "    X_test_info = X_test[contextual_col]\n",
    "    if train_proportion:\n",
    "            X_valid_info = X_valid[contextual_col]\n",
    "            \n",
    "    for col in contextual_col:\n",
    "        X_train.drop(col, axis=1, inplace=True)\n",
    "        X_test.drop(col, axis=1, inplace=True)\n",
    "        if train_proportion:\n",
    "            X_valid.drop(col, axis=1, inplace=True)\n",
    "\n",
    "    if train_proportion:\n",
    "        return (X_train_info, X_train, Y_train, X_test_info, X_test, Y_test, X_valid_info, X_valid, Y_valid)\n",
    "    else:\n",
    "        return (X_train_info, X_train, Y_train, X_test_info, X_test, Y_test)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
